\documentclass[12pt]{article}

\input preamble

\title{Principles of Parallel Architecture\\
Amdahl‚Äôs law and speed up}
\author{Xitong Liu \\
xliu@ece.udel.edu}

\begin{document}

\maketitle

\section{Serial Matrix Multiplication}
\begin{description}
\item[Requirement:] The first thing you need to do is to implement a C program 
for Matrix Multiplication, serially, for a single processor.

Your implementation will create and initialize 2 matrices of size N 
by N (that are called MatrixA and MatrixB) and multiply them (Store 
the result in a variable called MatrixC).

The value of N will be given to your program through the command line. 
The value of each element of the Matrices will be random double 
precision numbers from -1 to 1.

Also, for testing purposes, if N is less than 6, the program will 
automatically print to the screen matrices MatrixA, MatrixB and 
MatrixC.

\item[Q:] Put a copy of your program in the report.
\item[A:] 
Source Code:
\input code

\item[Q:] Make a table with the values of N, $T_{i}$, $T_{c}$, and 
$T_{T}$ for your report and plot T vs N for the initialization, 
computation and total time. Fit your curves to a polynomial of 
appropriate degree.

\item[A:] The curve is plotted in Fig.\ref{fig:serial_mm}. N, $T_{t}$, 
$T_{i}$ and $T_{c}$ were shown in Tab.\ref{tab:ntt}.

\begin{table}[t]
	\begin{center}
	\caption{\label{tab:ntt} N, $T_{t}$, $T_{i}$ and $T_{c}$}
	\begin{tabular}{|r|r|r|r|r|}
		\hline
		$T_{t}$ & N & $T_{t} (s)$ & $T_{i} (s)$ & $T_{c} (s)$ \\ \hline
		0.5 seconds & 360    & 0.502607    & 0.005212     & 0.497395 \\ \hline
		1 second    & 421    & 1.013100    & 0.007261     & 1.005839 \\ \hline
		2 seconds   & 514    & 2.097357    & 0.010981     & 2.086376 \\ \hline
		4 seconds   & 609    & 4.083775    & 0.015564     & 4.068211 \\ \hline
		8 seconds   & 737    & 7.995231    & 0.023209     & 7.972022 \\ \hline
		16 seconds  & 920    & 15.953456   & 0.035903     & 15.917553 \\ \hline
		32 seconds  & 1160   & 32.831239   & 0.057488     & 32.773751 \\ \hline
		1 minute    & 420    & 60.495999   & 0.081975     & 60.414024 \\ \hline
		2 minutes   & 1770   & 118.073772  & 0.125513     & 117.948259 \\ \hline
		4 minutes   & 2210   & 231.345677  & 0.194876     & 231.150801 \\ \hline
		8 minutes   & 2850   & 507.652142  & 0.338189     & 507.313953 \\ \hline
	\end{tabular}
	\end{center}
\end{table}

\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=1.0\textwidth, angle=0]{serial_mm.pdf}
		\caption{\label{fig:serial_mm}Serial Matrix Multiplication: Matrix Size vs Time}
	\end{center}
\end{figure}

\item[Q:] What is the equation that best fit to your data for each 
case? Include the values of all coefficients you need.
\item[A:] 
\begin{equation}
T_{i} = AN^{2} + BN + C
\end{equation}

\begin{equation}
T_{c} = AN^{3} + BN^{2} + CN + D
\end{equation}

\begin{equation}
T_{t} = AN^{3} + BN^{2} + CN + D
\end{equation}

\end{description}


\section{Parallel Matrix Multiplication}
\begin{description}
\item[Requirement:]
In this case, you will use MPI to parallelize your Matrix 
Multiply application. As before, the names for the matrices 
will be MatrixA, MatrixB and MatrixC. Also, the size of the 
matrices remain NxN and N is a parameter passed through the 
command line.

The number of MPI processes to use is decided when the program 
is launched. For example if you run your program with:
\begin{verbatim}
mpirun –np 7 mpi_matmult 5 
\end{verbatim}
There will be 7 processors working to achieve the multiplication 
of 5x5 matrices. As before, when N is less than 6, automatically 
print the matrices to the screen.

\item[Q:] Create a directory called \texttt{mpi\_matmult}. Put in that directory all 
your source code files and the makefile that will correctly compile 
the program. Create a rule called “run” that will run the program with N=5

\item[Q:] Explain carefully how your program makes the parallel matrix 
multiplication and how your program satisfies the requirements a to f. 
Uses examples and mathematical analysis also.

\item[A:] I tried to distribute the matrix data evenly between the processes,
and each process initialize and calculate the data on it's own. More 
specifically, \texttt{MatrixA} and \texttt{MatrixC} were split into N parts
horizontally while \texttt{MatrixB} was split into N parts vertically,
say, \texttt{sub-MatrixA}, \texttt{sub-MatrixB}, \texttt{sub-MatrixC}.
Then in a loop of N, each processes used \texttt{MPI\_Bcast} to send 
it's part of \texttt{MatrixB} to other peers, calculated the multiplication
of \texttt{sub-MatrixA} and received \texttt{sub-MatrixB} and stored the 
result in \texttt{sub-MatrixC}. When the loop was done, each of the processes
have the result ready in \texttt{sub-MatrixC}. As last, process \#0 collected 
the results in a message ring through \texttt{MPI\_Send} and \texttt{MPI\_Recv}, 
validating the result by comparing with results from serial multiplication.

For each process, the total storage is roughly $\frac{4N^2}{P}$, holding 
\texttt{sub-MatrixA}, \texttt{sub-MatrixB}, \texttt{sub-MatrixC} and one 
intermediate sub-Matrix with the same size of \texttt{sub-MatrixB} to hold 
the data from other processes. Only process \#0 hold extra data to hold the 
collected data and do validation.

\item[Q:] How do you manage the distribution of the data when the sizes 
of your blocks are not multiple of the sizes of the matrix? For example 
when N=79 using 7 MPI processes.

\item[A:] To make sure the data is distributed evenly in the processes,
I made a division on the matrix size. For example, $79 = 7 \times 11 + 2$,
so each process will hold at least $11$ rows (columns) of data. For the 
remainder $2$, it will distributed evenly in the first $2$ processes. Thus,
$79 = 7 \times 11 + 2 = 2 \times 12 + 5 \times 11$. More specifically, 
process $\#0$ and $\#1$ will hold $12$ rows (columns) and others holding $11$
rows (columns).

\item[Q:] For the values of N that you found on part 1., measure the times 
$T_i$, $T_c$, and $T_T$ from 2 to the maximum of MPI processes supported.

Report your results in a graph of speed up vs number of MPI processes 
for each value of N used in part 1. All your plots have to be in the 
same graph. For the speed up uses $T_{t}$.

\item[A:] See Fig.\ref{fig: parallel_mm}. T0.5, T1, T480 etc,. denote the cases 
with different matrix size $N$ that the serial version will take 
different time span, i.e 0.5s, 1s, 480s (8 min), to get the result, respectively.
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=1.0\textwidth, angle=0]{parallel_mm.pdf}
		\caption{\label{fig: parallel_mm}Parallel Speedup $T_{T}$: Speedup vs Process Number}
	\end{center}
\end{figure}

\item[Q:] What is the best and the worst speed up? Why?
\item[A:] The best speed up is 42.1412 times when N = 10 and the original time is 
32s. The worst speed up is 4.0365 times when N = 2 and the original time is 240s 
(4 min).

The result is obvious: the more processes run concurrently, the higher speed up 
it will gain. 

For T0.5 case, the matrix size is very small (360 by 360). The speed
up decreases slowly as the process number increases. This is because the overhead to
start MPI and exchange data between processes is much longer than the time to run 
the multiplication and dominate the total time cost. The more process, the more overhead, 
and the speed up decreases as a result.

\item[Q: ] Repeat e. and f. using only $T_{C}$ for calculating the speed up.
\item[A: ] See Fig.\ref{fig: parallel_mm_2}. The results are similar with 
Fig.\ref{fig: parallel_mm} in which $T_{T}$ is measured. 

\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=1.0\textwidth, angle=0]{parallel_mm_2.pdf}
		\caption{\label{fig: parallel_mm_2}Parallel Speedup $T_{C}$: Speedup vs Process Number}
	\end{center}
\end{figure}

The best speed up is 41.6632 times when N = 10 and the original time is 
32s. The worst speed up is 4.0502 times when N = 2 and the original time is 240s 
(4 min).

\item[Q: ] When is it a good idea to use parallel programming?
\item[A: ] When the data to be processed can be divided into non-overlap parts and can been 
processed separately, using parallel programming can gain great speed up.

\end{description}

\section{Amdahl’s Law}
\begin{description}
\item[Q:] Assume that your Matrix Multiply program is 0.5\% serial. What is the maximum 
speeding up that you can get using:
	\begin{enumerate}
		\item 2 processors?
		\item 10 processors?
		\item 1000 processors?
		\item 10000 processors?
		\item Infinite Processors?
	\end{enumerate}
	
\item[A:] According to Amdahl’s Law, the speed up 
\begin{equation}
S = \frac{1}{(1-P) + \frac{P}{N}}
\end{equation}
in which $P$ is the parallel part and $N$ is the number of processors. In this case, 
$P = 1 - 0.005 = 0.995$. For different values of $N$, the speed up is:

	\begin{enumerate}
		\item 2 processors, 1.9900
		\item 10 processors, 9.5693
		\item 1000 processors, 169.4915
		\item 10000 processors, 200.0000
		\item Infinite Processors, 200.0000
	\end{enumerate}
	
\end{description}

\end{document}

\begin{comment}
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=0.7\textwidth, angle=0]{fatest.png}
		\caption{\label{fig:fatest}Fatest SuperComputer in the world}
	\end{center}
\end{figure}
\end{comment}